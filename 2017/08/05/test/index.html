<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="换了一个主题之后Letax全都渲染不出来了，口亨！"><title>机器学习1：有趣的机器学习 | XxxSssSss</title><link rel="stylesheet" type="text/css" href="//fonts.css.network/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">机器学习1：有趣的机器学习</h1><a id="logo" href="/.">XxxSssSss</a><p class="description">啦啦啦~~~</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="Arama"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">机器学习1：有趣的机器学习</h1><div class="post-meta"><a href="/2017/08/05/test/#comments" class="comment-count"></a><p><span class="date">Aug 05, 2017</span><span><a href="/categories/机器学习笔记/" class="category">机器学习笔记</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><p>机器学习1：有趣的机器学习</p>
<p>TBC…</p>
<a id="more"></a>
<h1 id="机器学习方法"><a href="#机器学习方法" class="headerlink" title="机器学习方法"></a>机器学习方法</h1><h2 id="什么是机器学习？"><a href="#什么是机器学习？" class="headerlink" title="什么是机器学习？"></a>什么是机器学习？</h2><p>机器学习是</p>
<h2 id="五类常见的机器学习方法"><a href="#五类常见的机器学习方法" class="headerlink" title="五类常见的机器学习方法"></a>五类常见的机器学习方法</h2><ol>
<li>监督学习<br>数据 + 标签</li>
<li>非监督学习<br>数据</li>
<li>半监督学习</li>
<li>强化学习<br>从经验中总结提升</li>
<li>遗传算法<br>适者生存，不适者淘汰</li>
</ol>
<hr>
<h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><h2 id="科普-人工神经网络-VS-生物神经网络"><a href="#科普-人工神经网络-VS-生物神经网络" class="headerlink" title="科普: 人工神经网络 VS 生物神经网络"></a>科普: 人工神经网络 VS 生物神经网络</h2><h2 id="神经网络-Neural-Network"><a href="#神经网络-Neural-Network" class="headerlink" title="神经网络(Neural Network)"></a>神经网络(Neural Network)</h2><h2 id="卷积神经网络-CNN-Convolutional-Neural-Network"><a href="#卷积神经网络-CNN-Convolutional-Neural-Network" class="headerlink" title="卷积神经网络 CNN (Convolutional Neural Network)"></a>卷积神经网络 CNN (Convolutional Neural Network)</h2><p><strong>卷积：神经网络不再是对图片的每一个像素的输入信息做处理，而是对图像上每一小块像素区域做处理</strong><br>加强了图片信息的连续性，使得神经网络能看到图片的一个区域而不是一个点。<br>加强了神经网络对图片的理解<br>图片是有高度的，代表颜色。初始时，图像是黑白的，那么它的高度为1，彩色的则高度为3.<br>卷积的过程就是让图片面积逐渐变小、高度逐渐增高的过程。<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-060921.jpg" alt=""><br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-060954.jpg" alt=""><br>图片 卷积 边缘信息 卷积 五官 卷积 脸<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-061009.jpg" alt=""><br>池化：卷积时先不压缩图片，池化时统一压缩，避免丢失信息</p>
<p>图片 卷积 池化 卷积 池化 全连接神经网络 全连接神经网络 分类器</p>
<h2 id="循环神经网络-RNN-Recurrent-Neural-Network"><a href="#循环神经网络-RNN-Recurrent-Neural-Network" class="headerlink" title="循环神经网络 RNN (Recurrent Neural Network)"></a>循环神经网络 RNN (Recurrent Neural Network)</h2><h2 id="长短期记忆循环神经网络-LSTM-Long-Short-Term-Memory"><a href="#长短期记忆循环神经网络-LSTM-Long-Short-Term-Memory" class="headerlink" title="长短期记忆循环神经网络 LSTM (Long-Short Term Memory)"></a>长短期记忆循环神经网络 LSTM (Long-Short Term Memory)</h2><h2 id="自编码-Autoencoder"><a href="#自编码-Autoencoder" class="headerlink" title="自编码 (Autoencoder)"></a>自编码 (Autoencoder)</h2><p>神经网络的非监督学习</p>
<h2 id="生成对抗网络-GAN-Generative-Adversarial-Nets"><a href="#生成对抗网络-GAN-Generative-Adversarial-Nets" class="headerlink" title="生成对抗网络 GAN (Generative Adversarial Nets)"></a>生成对抗网络 GAN (Generative Adversarial Nets)</h2><h3 id="新手鉴赏家和新手画家"><a href="#新手鉴赏家和新手画家" class="headerlink" title="新手鉴赏家和新手画家"></a>新手鉴赏家和新手画家</h3><p>新手画家用随机灵感画画 , 新手鉴赏家会接收一些画作, 但是他不知道这是新手画家画的还是著名画家画的, 他说出他的判断, 你来纠正他的判断, 新手鉴赏家一边学如何判断, 一边告诉新手画家要怎么画才能画得更像著名画家, 新手画家就能学习到如何从自己的灵感画出更像著名画家的画了. GAN 也就这么回事.<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-064826.jpg" alt=""></p>
<h3 id="GAN-网络"><a href="#GAN-网络" class="headerlink" title="GAN 网络"></a>GAN 网络</h3><p>Generator 会根据随机数来生成有意义的数据 , Discriminator 会学习如何判断哪些是真实数据 , 哪些是生成数据, 然后将学习的经验反向传递给 Generator, 让 Generator 能根据随机数生成更像真实数据的数据. 这样训练出来的 Generator 可以有很多用途, 比如最近有人就拿它来生成各种卧室的图片.<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-064937.jpg" alt=""></p>
<h2 id="科普-神经网络的黑盒不黑"><a href="#科普-神经网络的黑盒不黑" class="headerlink" title="科普: 神经网络的黑盒不黑"></a>科普: 神经网络的黑盒不黑</h2><p>代表特征<br>迁移学习</p>
<h2 id="神经网络-梯度下降"><a href="#神经网络-梯度下降" class="headerlink" title="神经网络 梯度下降"></a>神经网络 梯度下降</h2><p>神经网络是当今为止最流行的一种深度学习框架, 他的基本原理也很简单, 就是一种梯度下降机制。</p>
<p>优化问题Optimization<br>牛顿法 (Newton’s method), 最小二乘法(Least Squares method), 梯度下降法 (Gradient Descent) </p>
<hr>
<h1 id="神经网络技巧"><a href="#神经网络技巧" class="headerlink" title="神经网络技巧"></a>神经网络技巧</h1><h2 id="检验神经网络-Evaluation"><a href="#检验神经网络-Evaluation" class="headerlink" title="检验神经网络 (Evaluation)"></a>检验神经网络 (Evaluation)</h2><p>检验标准：<br>误差曲线  横坐标 时间<br>精确度曲线 横坐标 时间 一般用于分类问题<br>R2分数 测量回归问题的精度<br>F1分数 用于测量不均衡数据的精度</p>
<p>过分依赖训练样本会过拟合<br>解决措施：l1, l2 正规化, dropout 方法.</p>
<p>参数<br>交叉验证不仅仅可以用于神经网络的调参, 还能用于其他机器学习方法的调参.<br>横坐标 某参数</p>
<h2 id="特征标准化-Feature-Normalization"><a href="#特征标准化-Feature-Normalization" class="headerlink" title="特征标准化 (Feature Normalization)"></a>特征标准化 (Feature Normalization)</h2><p>特征数据的标准化, 也可以说正常化, 归一化, 正规化等等.<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-072731.jpg" alt=""><br>我们在机器学习训练之前, 先对数据预先处理一下, 取值跨度大的特征数据, 我们浓缩一下, 跨度小的括展一下, 使得他们的跨度尽量统一.<br>通常用于 特征标准化的途径有两种, 一种叫做 min max normalization, 他会将所有特征数据按比例缩放到0-1的这个取值区间. 有时也可以是-1到1的区间. 还有一种叫做 standard deviation normalization, 他会将所有特征数据缩放成 平均值为0, 方差为1.<br><strong>使用这些标准化手段. 我们不仅可以快速推进机器学习的学习速度, 还可以避免机器学习学得特扭曲.</strong></p>
<h2 id="选择好特征-Good-Features"><a href="#选择好特征-Good-Features" class="headerlink" title="选择好特征 (Good Features)"></a>选择好特征 (Good Features)</h2><p>我们用特征描述一个物体, 比如在A, B两种类型中, 我们有长度, 颜色两种特征属性. 那么在用这些特征描述类别的时候, 好的特征能够让我们更轻松辨别出相应特征所代表的类别. 而不好的特征, 会混乱我们的感官, 带来些没有用的信息, 浪费了我们的分析,计算资源.</p>
<p>我们想要区分金毛和吉娃娃，那么高度就是一个很好的特征：<br><figure class="highlight python"><figcaption><span>金毛与吉娃娃</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span>
<span class="line">2</span>
<span class="line">3</span>
<span class="line">4</span>
<span class="line">5</span>
<span class="line">6</span>
<span class="line">7</span>
<span class="line">8</span>
<span class="line">9</span>
<span class="line">10</span>
<span class="line">11</span>
</pre></td><td class="code"><pre><span class="line"><span class="comment"># -*-coding:utf-8-*-</span></span>
<span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span>
<span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span>
<span class="line"></span>
<span class="line">gold, chihh = <span class="number">400</span>, <span class="number">400</span></span>
<span class="line"></span>
<span class="line">gold_height = <span class="number">40</span> + <span class="number">10</span> * np.random.randn(gold)</span>
<span class="line">chihh_height = <span class="number">25</span> + <span class="number">6</span> * np.random.rand(chihh)</span>
<span class="line"></span>
<span class="line">plt.hist([gold_height, chihh_height], stacked=<span class="keyword">True</span>, color=[<span class="string">'r'</span>, <span class="string">'b'</span>])</span>
<span class="line">plt.show()</span>
</pre></td></tr></table></figure></p>
<p>高度是一个很有用的特征, 但是并不完美, 这就是我们为什么需要整合更多的特征来处理机器学习中的问题.</p>
<p>挑选特征信息：</p>
<ul>
<li>避免无意义信息</li>
<li>避免重复性信息</li>
<li>避免复杂的信息</li>
</ul>
<h2 id="激励函数-Activation-Function"><a href="#激励函数-Activation-Function" class="headerlink" title="激励函数 (Activation Function)"></a>激励函数 (Activation Function)</h2><p><strong>激励函数是为了解决我们日常生活中不能用线性方程所概括的问题. </strong></p>
<p>说到线性方程, 我们不得不提到另外一种方程, 非线性方程 (nonlinear function). 我们假设, 女生长得越漂亮, 越多男生爱. 这就可以被当做一个线性问题. 但是如果我们假设这个场景是发生在校园里. 校园里的男生数是有限的, 女生再漂亮, 也不可能会有无穷多的男生喜欢她. 所以这就变成了一个非线性问题.</p>
<p>然后我们就可以来讨论如何在神经网络中达成我们描述非线性的任务了. 我们可以把整个网络简化成这样一个式子. Y = Wx, W 就是我们要求的参数, y 是预测值, x 是输入值. 用这个式子, 我们很容易就能描述刚刚的那个线性问题, 因为 W 求出来可以是一个固定的数. 不过这似乎并不能让这条直线变得扭起来 , 激励函数见状, 拔刀相助, 站出来说道: “让我来掰弯它!”.</p>
<p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-082703.jpg" alt=""><br>这里的 AF 就是指的激励函数. 激励函数拿出自己最擅长的”掰弯利器”, 套在了原函数上 用力一扭, 原来的 Wx 结果就被扭弯了.</p>
<p>其实这个 AF, 掰弯利器, 也不是什么触不可及的东西. 它其实就是另外一个非线性函数. 比如说relu, sigmoid, tanh. 将这些掰弯利器嵌套在原有的结果之上, 强行把原有的线性结果给扭曲了. 使得输出结果 y 也有了非线性的特征. 举个例子, 比如我使用了 relu 这个掰弯利器, 如果此时 Wx 的结果是1, y 还将是1, 不过 Wx 为-1的时候, y 不再是-1, 而会是0.</p>
<p>你甚至可以创造自己的激励函数来处理自己的问题, 不过要确保的是这些激励函数必须是可以微分的, 因为在 backpropagation 误差反向传递的时候, 只有这些可微分的激励函数才能把误差传递回去.<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-082828.jpg" alt=""><br>在少量层结构中, 我们可以尝试很多种不同的激励函数. 在卷积神经网络 Convolutional neural networks 的卷积层中, 推荐的激励函数是 relu. 在循环神经网络中 recurrent neural networks, 推荐的是 tanh 或者是 relu (这个具体怎么选, 我会在以后 循环神经网络的介绍中在详细讲解).</p>
<h2 id="过拟合-Overfitting"><a href="#过拟合-Overfitting" class="headerlink" title="过拟合 (Overfitting)"></a>过拟合 (Overfitting)</h2><p>解决方法<br><strong>方法一:</strong><br>增加数据量, 大部分过拟合产生的原因是因为数据量太少了. 如果我们有成千上万的数据, 红线也会慢慢被拉直, 变得没那么扭曲.<br><strong>方法二:</strong><br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-092133.jpg" alt=""><br>运用正规化. L1, l2 regularization等等, 这些方法适用于大多数的机器学习, 包括神经网络. 他们的做法大同小异, 我们简化机器学习的关键公式为 y=Wx . W为机器需要学习到的各种参数. 在过拟合中, W 往往变化率比较大. 为了不让W一次性变化太大, 我们在计算误差上做些手脚. 原始的 cost 误差是这样计算 , cost = 预测值-真实值的平方. 如果 W 变得太大, 我们就让 cost 也跟着变大, 变成一种惩罚机制. 所以我们把 W 自己考虑进来 . 这里 abs 是绝对值. 这一种形式的 正规化, 叫做 l1 正规化. L2 正规化和l1 类似, , 只是绝对值换成了平方. 其他的l3.l4 也都是换成了立方和4次方等等. 形式类似. 用这些方法,我们就能保证让学出来的线条不会过于扭曲.<br><strong>方法三:</strong><br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-092220.jpg" alt=""><br>还有一种专门用在神经网络的正规化的方法, 叫作 dropout. 在训练的时候, 我们随机忽略掉一些神经元和神经联结 , 是这个神经网络变得”不完整”. 用一个不完整的神经网络训练一次.</p>
<p>到第二次再随机忽略另一些 , 变成另一个不完整的神经网络. 有了这些随机 drop 掉的规则, 我们可以想象其实每次训练的时候, 我们都让每一次预测结果都不会依赖于其中某部分特定的神经元. 像l1, l2正规化一样, 过度依赖的 W , 也就是训练参数的数值会很大, l1, l2会惩罚这些大的参数. Dropout 的做法是从根本上让神经网络没机会过度依赖.</p>
<h2 id="加速神经网络训练-Speed-Up-Training"><a href="#加速神经网络训练-Speed-Up-Training" class="headerlink" title="加速神经网络训练 (Speed Up Training)"></a>加速神经网络训练 (Speed Up Training)</h2><p>包括以下几种模式:</p>
<ul>
<li>Stochastic Gradient Descent (SGD)</li>
<li>Momentum</li>
<li>AdaGrad</li>
<li>RMSProp</li>
<li>Adam</li>
</ul>
<p>越复杂的神经网络 , 越多的数据 , 我们需要在训练神经网络的过程上花费的时间也就越多. 原因很简单, 就是因为计算量太大了. 可是往往有时候为了解决复杂的问题, 复杂的结构和大数据又是不能避免的, 所以我们需要寻找一些方法, 让神经网络聪明起来, 快起来.</p>
<h3 id="Stochastic-Gradient-Descent-SGD"><a href="#Stochastic-Gradient-Descent-SGD" class="headerlink" title="Stochastic Gradient Descent (SGD)"></a>Stochastic Gradient Descent (SGD)</h3><p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-094923.jpg" alt=""><br>所以, 最基础的方法就是 SGD 啦, 想像红色方块是我们要训练的 data, 如果用普通的训练方法, 就需要重复不断的把整套数据放入神经网络 NN训练, 这样消耗的计算资源会很大.</p>
<p>我们换一种思路, 如果把这些数据拆分成小批小批的, 然后再分批不断放入 NN 中计算, 这就是我们常说的 SGD 的正确打开方式了. 每次使用批数据, 虽然不能反映整体数据的情况, 不过却很大程度上加速了 NN 的训练过程, 而且也不会丢失太多准确率.如果运用上了 SGD, 你还是嫌训练速度慢, 那怎么办?</p>
<h3 id="Momentum-更新方法"><a href="#Momentum-更新方法" class="headerlink" title="Momentum 更新方法"></a>Momentum 更新方法</h3><p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-095043.jpg" alt=""><br>大多数其他途径是在更新神经网络参数那一步上动动手脚. 传统的参数 W 的更新是把原始的 W 累加上一个负的学习率(learning rate) 乘以校正值 (dx). 这种方法可能会让学习过程曲折无比, 看起来像 喝醉的人回家时, 摇摇晃晃走了很多弯路.<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-095101.jpg" alt=""><br>所以我们把这个人从平地上放到了一个斜坡上, 只要他往下坡的方向走一点点, 由于向下的惯性, 他不自觉地就一直往下走, 走的弯路也变少了. 这就是 Momentum 参数更新. 另外一种加速方法叫AdaGrad.</p>
<h3 id="AdaGrad-更新方法"><a href="#AdaGrad-更新方法" class="headerlink" title="AdaGrad 更新方法"></a>AdaGrad 更新方法</h3><p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-095127.jpg" alt=""><br>这种方法是在学习率上面动手脚, 使得每一个参数更新都会有自己与众不同的学习率, 他的作用和 momentum 类似, 不过不是给喝醉酒的人安排另一个下坡, 而是给他一双不好走路的鞋子, 使得他一摇晃着走路就脚疼, 鞋子成为了走弯路的阻力, 逼着他往前直着走. 他的数学形式是这样的. 接下来又有什么方法呢? 如果把下坡和不好走路的鞋子合并起来, 是不是更好呢? 没错, 这样我们就有了 RMSProp 更新方法.</p>
<h3 id="RMSProp-更新方法"><a href="#RMSProp-更新方法" class="headerlink" title="RMSProp 更新方法"></a>RMSProp 更新方法</h3><p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-095146.jpg" alt=""><br>有了 momentum 的惯性原则 , 加上 adagrad 的对错误方向的阻力, 我们就能合并成这样. 让 RMSProp同时具备他们两种方法的优势. 不过细心的同学们肯定看出来了, 似乎在 RMSProp 中少了些什么. 原来是我们还没把 Momentum合并完全, RMSProp 还缺少了 momentum 中的 这一部分. 所以, 我们在 Adam 方法中补上了这种想法.</p>
<h3 id="Adam-更新方法"><a href="#Adam-更新方法" class="headerlink" title="Adam 更新方法"></a>Adam 更新方法</h3><p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-095207.jpg" alt=""><br>计算m 时有 momentum 下坡的属性, 计算 v 时有 adagrad 阻力的属性, 然后再更新参数时 把 m 和 V 都考虑进去. 实验证明, 大多数时候, 使用 adam 都能又快又好的达到目标, 迅速收敛. 所以说, 在加速神经网络训练的时候, 一个下坡, 一双破鞋子, 功不可没.</p>
<h2 id="处理不均衡数据-Imbalanced-data"><a href="#处理不均衡数据-Imbalanced-data" class="headerlink" title="处理不均衡数据 (Imbalanced data)"></a>处理不均衡数据 (Imbalanced data)</h2><ol>
<li>获取更多数据<ul>
<li>首先, 我们要想想, 自己还能不能获取到更多的数据. 有时候只是因为前段时期的数据多半呈现的是一种趋势, 等到后半时期趋势又不一样了. 如果没有获取后半时期的数据, 整体的预测可能就没有那么准确了.</li>
</ul>
</li>
<li>更换评判方式<ul>
<li>通常, 我们会用到 准确率 accuracy, 或者误差 cost来判断机器学习的成果. 可是这些评判方法在不均衡数据面前, 高的准确率和低的误差变得没那么重要. 所以我们得换一种方式评判. 通过 confusion matrix 来计算 precision 和 recall, 然后通过 precision 和 recall 再计算f1 分数.这种方式能成功地区分不均衡数据, 给出更好的评判分数.</li>
</ul>
</li>
<li>重组数据<ul>
<li>复制或者合成少数部分的样本, 使之和多数部分差不多数量. </li>
<li>砍掉一些多数部分, 使两者数量差不多.</li>
</ul>
</li>
<li>其他机器学习算法<ul>
<li>神经网络等, 在面对不均衡数据时, 通常是束手无策. 不过有些机器学习方法, 像决策树, decision trees 就不会受到不均很数据的影响.</li>
</ul>
</li>
<li>修改算法<ul>
<li>如，调整激励函数的预测门槛</li>
</ul>
</li>
</ol>
<h2 id="批标准化-Batch-Normalization"><a href="#批标准化-Batch-Normalization" class="headerlink" title="批标准化 (Batch Normalization)"></a>批标准化 (Batch Normalization)</h2><p><strong>BN本质上解决的是反向传播过程中的梯度问题（梯度消失和爆炸），同时使得不同scale的 w 整体更新步调更一致。</strong><br><a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-08-batch-normalization/" target="_blank" rel="external">视频戳这里</a><br><a href="https://www.zhihu.com/question/38102762" target="_blank" rel="external">知乎参考</a></p>
<h3 id="BN-添加位置"><a href="#BN-添加位置" class="headerlink" title="BN 添加位置"></a>BN 添加位置</h3><p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-101233.jpg" alt=""><br>Batch normalization 的 batch 是批数据, 把数据分成小批小批进行 stochastic gradient descent. 而且在每批数据进行前向传递 forward propagation 的时候, 对每一层都进行 normalization 的处理。</p>
<h3 id="BN-效果"><a href="#BN-效果" class="headerlink" title="BN 效果"></a>BN 效果</h3><p>Batch normalization 也可以被看做一个层面. 在一层层的添加神经网络的时候, 我们先有数据 X, 再添加全连接层, 全连接层的计算结果会经过 激励函数 成为下一层的输入, 接着重复之前的操作. Batch Normalization (BN) 就被添加在每一个全连接和激励函数之间.<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-101331.jpg" alt=""><br>之前说过, 计算结果在进入激励函数前的值很重要, 如果我们不单单看一个值, 我们可以说, 计算结果值的分布对于激励函数很重要. 对于数据值大多分布在这个区间的数据, 才能进行更有效的传递. 对比这两个在激活之前的值的分布. 上者没有进行 normalization, 下者进行了 normalization, 这样当然是下者能够更有效地利用 tanh 进行非线性化的过程.<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-101421.jpg" alt=""><br>没有 normalize 的数据 使用 tanh 激活以后, 激活值大部分都分布到了饱和阶段, 也就是大部分的激活值不是-1, 就是1, 而 normalize 以后, 大部分的激活值在每个分布区间都还有存在. 再将这个激活后的分布传递到下一层神经网络进行后续计算, 每个区间都有分布的这一种对于神经网络就会更加有价值.</p>
<h2 id="L1-L2-正规化-Regularization"><a href="#L1-L2-正规化-Regularization" class="headerlink" title="L1 / L2 正规化 (Regularization)"></a>L1 / L2 正规化 (Regularization)</h2><p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-102506.jpg" alt=""></p>
<h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-102559.jpg" alt=""><br>我们拿 L2正规化来探讨一下, 机器学习的过程是一个 通过修改参数 theta 来减小误差的过程, 可是在减小误差的时候非线性越强的参数, 比如在 x^3 旁边的 theta 4 就会被修改得越多, 因为如果使用非线性强的参数就能使方程更加曲折, 也就能更好的拟合上那些分布的数据点. Theta 4 说, 瞧我本事多大, 就让我来改变模型, 来拟合所有的数据吧, 可是它这种态度招到了误差方程的强烈反击, 误差方程就说: no no no no, 我们是一个团队, 虽然你厉害, 但也不能仅仅靠你一个人, 万一你错了, 我们整个团队的效率就突然降低了, 我得 hold 住那些在 team 里独出风头的人. 这就是整套正规化算法的核心思想. 那 L1, L2 正规化又有什么不同呢?</p>
<h3 id="图像化"><a href="#图像化" class="headerlink" title="图像化"></a>图像化</h3><p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-102551.jpg" alt=""><br>想象现在只有两个参数 theta1 theta2 要学, 蓝色的圆心是误差最小的地方, 而每条蓝线上的误差都是一样的. 正规化的方程是在黄线上产生的额外误差(也能理解为惩罚度), 在黄圈上的额外误差也是一样. 所以在蓝线和黄线 交点上的点能让两个误差的合最小. 这就是 theta1 和 theta2 正规化后的解. 要提到另外一点是, 使用 L1 的方法, 我们很可能得到的结果是只有 theta1 的特征被保留, 所以很多人也用 l1 正规化来挑选对结果贡献最大的重要特征. 但是 l1 的结并不是稳定的. 比如用批数据训练, 每次批数据都会有稍稍不同的误差曲线,<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-102633.jpg" alt=""><br>L2 针对于这种变动, 白点的移动不会太大, 而 L1的白点则可能跳到许多不同的地方 , 因为这些地方的总误差都是差不多的. 侧面说明了 L1 解的不稳定性.</p>
<h3 id="统一表达形式"><a href="#统一表达形式" class="headerlink" title="统一表达形式"></a>统一表达形式</h3><p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-102656.jpg" alt=""><br>最后,为了控制这种正规化的强度, 我们会加上一个参数 lambda, 并且通过 交叉验证 cross validation 来选择比较好的 lambda. 这时, 为了统一化这类型的正规化方法, 我们还会使用 p 来代表对参数的正规化程度. 这就是这一系列正规化方法的最终的表达形式啦.</p>
<hr>
<h1 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h1><p><strong>强化学习是一个通过奖惩来学习正确行为的机制.</strong></p>
<h2 id="强化学习-Reinforcement-Learning"><a href="#强化学习-Reinforcement-Learning" class="headerlink" title="强化学习 (Reinforcement Learning)"></a>强化学习 (Reinforcement Learning)</h2><p>分数导向性</p>
<h3 id="从无到有"><a href="#从无到有" class="headerlink" title="从无到有"></a>从无到有</h3><p><strong>强化学习是一类算法, 是让计算机实现从一开始什么都不懂, 脑袋里没有一点想法, 通过不断地尝试, 从错误中学习, 最后找到规律, 学会了达到目的的方法.</strong> 这就是一个完整的强化学习过程. 实际中的强化学习例子有很多. 比如近期最有名的 Alpha go, 机器头一次在围棋场上战胜人类高手, 让计算机自己学着玩经典游戏 Atari, 这些都是让计算机在不断的尝试中更新自己的行为准则, 从而一步步学会如何下好围棋, 如何操控游戏得到高分. 既然要让计算机自己学, 那计算机通过什么来学习呢?</p>
<h3 id="虚拟老师"><a href="#虚拟老师" class="headerlink" title="虚拟老师"></a>虚拟老师</h3><p>原来计算机也需要一位虚拟的老师, 这个老师比较吝啬, 他不会告诉你如何移动, 如何做决定, 他为你做的事只有给你的行为打分, 那我们应该以什么形式学习这些现有的资源, 或者说怎么样只从分数中学习到我应该怎样做决定呢? 很简单, 我只需要记住那些高分, 低分对应的行为, 下次用同样的行为拿高分, 并避免低分的行为.</p>
<p>比如老师会根据我的开心程度来打分, 我开心时, 可以得到高分, 我不开心时得到低分. 有了这些被打分的经验, 我就能判断为了拿到高分, 我应该选择一张开心的脸, 避免选到伤心的脸. 这也是强化学习的核心思想. 可以看出在强化学习中, 一种行为的分数是十分重要的. 所以强化学习具有分数导向性. 我们换一个角度来思考.这种分数导向性好比我们在监督学习中的正确标签.</p>
<h3 id="对比监督学习"><a href="#对比监督学习" class="headerlink" title="对比监督学习"></a>对比监督学习</h3><p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-130814.jpg" alt=""></p>
<p>我们知道监督学习, 是已经有了数据和数据对应的正确标签, 比如这样. 监督学习就能学习出那些脸对应哪种标签. 不过强化学习还要更进一步, 一开始它并没有数据和标签.</p>
<p>他要通过一次次在环境中的尝试, 获取这些数据和标签, 然后再学习通过哪些数据能够对应哪些标签, 通过学习到的这些规律, 竟可能地选择带来高分的行为 (比如这里的开心脸). 这也就证明了在强化学习中, 分数标签就是他的老师, 他和监督学习中的老师也差不多.</p>
<h2 id="强化学习方法汇总-Reinforcement-Learning"><a href="#强化学习方法汇总-Reinforcement-Learning" class="headerlink" title="强化学习方法汇总 (Reinforcement Learning)"></a>强化学习方法汇总 (Reinforcement Learning)</h2><p><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-131529.jpg" alt=""><br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-131516.jpg" alt=""><br>在基于概率这边, 有 policy gradients, 在基于价值这边有 q learning, sarsa 等. 而且我们还能结合这两类方法的优势之处, 创造更牛逼的一种方法, 叫做 actor-critic, actor 会基于概率做出动作, 而 critic 会对做出的动作给出动作的价值, 这样就在原有的 policy gradients 上加速了学习过程.<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-131552.jpg" alt=""><br>Monte-carlo learning 和基础版的 policy gradients 等 都是回合更新制, Qlearning, Sarsa, 升级版的 policy gradients 等都是单步更新制. 因为单步更新更有效率, 所以现在大多方法都是基于单步更新. 比如有的强化学习问题并不属于回合问题.<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-05-131617.jpg" alt=""><br>最典型的在线学习就是 sarsa 了, 还有一种优化 sarsa 的算法, 叫做 sarsa lambda, 最典型的离线学习就是 Q learning, 后来人也根据离线学习的属性, 开发了更强大的算法, 比如让计算机学会玩电动的 Deep-Q-Network.</p>
<h2 id="Q-Leaning"><a href="#Q-Leaning" class="headerlink" title="Q Leaning"></a>Q Leaning</h2><h2 id="Sarsa"><a href="#Sarsa" class="headerlink" title="Sarsa"></a>Sarsa</h2><h2 id="Sarsa-lambda"><a href="#Sarsa-lambda" class="headerlink" title="Sarsa(lambda)"></a>Sarsa(lambda)</h2><h2 id="DQN-Deep-Q-Network"><a href="#DQN-Deep-Q-Network" class="headerlink" title="DQN (Deep Q Network)"></a>DQN (Deep Q Network)</h2><p>神经网络 + Q Learning<br><img src="http://onk12tr6m.bkt.clouddn.com/2017-08-06-061236.jpg" alt=""><br>DQN 有一个记忆库用于学习之前的经历.  Q learning 是一种 off-policy 离线学习法, 它能学习当前经历着的, 也能学习过去经历过的, 甚至是学习别人的经历. 所以每次 DQN 更新的时候, 我们都可以随机抽取一些之前的经历进行学习. 随机抽取这种做法打乱了经历之间的相关性, 也使得神经网络更新更有效率.</p>
<h2 id="Policy-Gradients"><a href="#Policy-Gradients" class="headerlink" title="Policy Gradients"></a>Policy Gradients</h2><h2 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor Critic"></a>Actor Critic</h2><h2 id="Deep-Deterministic-Policy-Gradient-DDPG"><a href="#Deep-Deterministic-Policy-Gradient-DDPG" class="headerlink" title="Deep Deterministic Policy Gradient (DDPG)"></a>Deep Deterministic Policy Gradient (DDPG)</h2><p>DDPG 最大的优势就是能够在连续动作上更有效地学习.<br>它吸收了 Actor critic 让 Policy gradient 单步更新的精华, 而且还吸收让计算机学会玩游戏的 DQN 的精华, 合并成了一种新算法, 叫做 Deep Deterministic Policy Gradient. </p>
<h2 id="Asynchronous-Advantage-Actor-Critic-A3C"><a href="#Asynchronous-Advantage-Actor-Critic-A3C" class="headerlink" title="Asynchronous Advantage Actor-Critic (A3C)"></a>Asynchronous Advantage Actor-Critic (A3C)</h2><hr>
<h1 id="遗传算法"><a href="#遗传算法" class="headerlink" title="遗传算法"></a>遗传算法</h1><h2 id="遗传算法-Genetic-Algorithm"><a href="#遗传算法-Genetic-Algorithm" class="headerlink" title="遗传算法 (Genetic Algorithm)"></a>遗传算法 (Genetic Algorithm)</h2><hr>
<p><strong>参考资料</strong><br><a href="https://morvanzhou.github.io/tutorials/" target="_blank" rel="external">莫烦Python</a><br><a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/" target="_blank" rel="external">有趣的机器学习</a></p>
</div><div class="tags"><a href="/tags/sklearn/">sklearn</a></div><div class="post-share"><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到：</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2017/08/11/Deep-Learning/" class="pre">【深度学习】深度神经网络入门</a><a href="/2017/08/04/系统中多版本Python的切换与Python第三方库的安装/" class="next">系统中多版本Python的切换与Python第三方库的安装</a></div><div id="comments"></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#机器学习方法"><span class="toc-text">机器学习方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是机器学习？"><span class="toc-text">什么是机器学习？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#五类常见的机器学习方法"><span class="toc-text">五类常见的机器学习方法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#神经网络"><span class="toc-text">神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#科普-人工神经网络-VS-生物神经网络"><span class="toc-text">科普: 人工神经网络 VS 生物神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络-Neural-Network"><span class="toc-text">神经网络(Neural Network)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积神经网络-CNN-Convolutional-Neural-Network"><span class="toc-text">卷积神经网络 CNN (Convolutional Neural Network)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#循环神经网络-RNN-Recurrent-Neural-Network"><span class="toc-text">循环神经网络 RNN (Recurrent Neural Network)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#长短期记忆循环神经网络-LSTM-Long-Short-Term-Memory"><span class="toc-text">长短期记忆循环神经网络 LSTM (Long-Short Term Memory)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#自编码-Autoencoder"><span class="toc-text">自编码 (Autoencoder)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#生成对抗网络-GAN-Generative-Adversarial-Nets"><span class="toc-text">生成对抗网络 GAN (Generative Adversarial Nets)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#新手鉴赏家和新手画家"><span class="toc-text">新手鉴赏家和新手画家</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GAN-网络"><span class="toc-text">GAN 网络</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#科普-神经网络的黑盒不黑"><span class="toc-text">科普: 神经网络的黑盒不黑</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络-梯度下降"><span class="toc-text">神经网络 梯度下降</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#神经网络技巧"><span class="toc-text">神经网络技巧</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#检验神经网络-Evaluation"><span class="toc-text">检验神经网络 (Evaluation)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特征标准化-Feature-Normalization"><span class="toc-text">特征标准化 (Feature Normalization)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#选择好特征-Good-Features"><span class="toc-text">选择好特征 (Good Features)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#激励函数-Activation-Function"><span class="toc-text">激励函数 (Activation Function)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#过拟合-Overfitting"><span class="toc-text">过拟合 (Overfitting)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#加速神经网络训练-Speed-Up-Training"><span class="toc-text">加速神经网络训练 (Speed Up Training)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Stochastic-Gradient-Descent-SGD"><span class="toc-text">Stochastic Gradient Descent (SGD)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Momentum-更新方法"><span class="toc-text">Momentum 更新方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AdaGrad-更新方法"><span class="toc-text">AdaGrad 更新方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RMSProp-更新方法"><span class="toc-text">RMSProp 更新方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Adam-更新方法"><span class="toc-text">Adam 更新方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#处理不均衡数据-Imbalanced-data"><span class="toc-text">处理不均衡数据 (Imbalanced data)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#批标准化-Batch-Normalization"><span class="toc-text">批标准化 (Batch Normalization)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#BN-添加位置"><span class="toc-text">BN 添加位置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BN-效果"><span class="toc-text">BN 效果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#L1-L2-正规化-Regularization"><span class="toc-text">L1 / L2 正规化 (Regularization)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#核心思想"><span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#图像化"><span class="toc-text">图像化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#统一表达形式"><span class="toc-text">统一表达形式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#强化学习"><span class="toc-text">强化学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#强化学习-Reinforcement-Learning"><span class="toc-text">强化学习 (Reinforcement Learning)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#从无到有"><span class="toc-text">从无到有</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#虚拟老师"><span class="toc-text">虚拟老师</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#对比监督学习"><span class="toc-text">对比监督学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#强化学习方法汇总-Reinforcement-Learning"><span class="toc-text">强化学习方法汇总 (Reinforcement Learning)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Q-Leaning"><span class="toc-text">Q Leaning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sarsa"><span class="toc-text">Sarsa</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sarsa-lambda"><span class="toc-text">Sarsa(lambda)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DQN-Deep-Q-Network"><span class="toc-text">DQN (Deep Q Network)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Policy-Gradients"><span class="toc-text">Policy Gradients</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Actor-Critic"><span class="toc-text">Actor Critic</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deep-Deterministic-Policy-Gradient-DDPG"><span class="toc-text">Deep Deterministic Policy Gradient (DDPG)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Asynchronous-Advantage-Actor-Critic-A3C"><span class="toc-text">Asynchronous Advantage Actor-Critic (A3C)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#遗传算法"><span class="toc-text">遗传算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#遗传算法-Genetic-Algorithm"><span class="toc-text">遗传算法 (Genetic Algorithm)</span></a></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/08/11/Deep-Learning/">【深度学习】深度神经网络入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/05/test/">机器学习1：有趣的机器学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/04/系统中多版本Python的切换与Python第三方库的安装/">系统中多版本Python的切换与Python第三方库的安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/22/位运算/">位运算</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/21/剑指offer-31-40/">剑指offer 31~40</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/21/vector的初始化/">【C++】vector介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/19/stringstream/">【C++】stringstream的使用方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/10/Tensorflow5/">【神经网络】通过代码学习Tensorflow5</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/05/Tensorflow4/">【神经网络】通过代码学习Tensorflow4</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/04/Tensorflow3/">【神经网络】通过代码学习Tensorflow3</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C-笔记/">C++笔记</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术文档/">技术文档</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习笔记/">机器学习笔记</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂记/">杂记</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习笔记/">深度学习笔记</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法学习笔记/">算法学习笔记</a><span class="category-list-count">12</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/信息学/" style="font-size: 15px;">信息学</a> <a href="/tags/近似算法/" style="font-size: 15px;">近似算法</a> <a href="/tags/Graham-s-Scan/" style="font-size: 15px;">Graham's Scan</a> <a href="/tags/基本概念/" style="font-size: 15px;">基本概念</a> <a href="/tags/数学/" style="font-size: 15px;">数学</a> <a href="/tags/线性代数/" style="font-size: 15px;">线性代数</a> <a href="/tags/概率论/" style="font-size: 15px;">概率论</a> <a href="/tags/数值计算/" style="font-size: 15px;">数值计算</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/权值衰减/" style="font-size: 15px;">权值衰减</a> <a href="/tags/范数/" style="font-size: 15px;">范数</a> <a href="/tags/分治算法/" style="font-size: 15px;">分治算法</a> <a href="/tags/动态规划/" style="font-size: 15px;">动态规划</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/贪心/" style="font-size: 15px;">贪心</a> <a href="/tags/数学基础/" style="font-size: 15px;">数学基础</a> <a href="/tags/MathJax/" style="font-size: 15px;">MathJax</a> <a href="/tags/LaTex/" style="font-size: 15px;">LaTex</a> <a href="/tags/Markdown/" style="font-size: 15px;">Markdown</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Matplotlib/" style="font-size: 15px;">Matplotlib</a> <a href="/tags/感知机/" style="font-size: 15px;">感知机</a> <a href="/tags/sigmoid神经元/" style="font-size: 15px;">sigmoid神经元</a> <a href="/tags/神经网络/" style="font-size: 15px;">神经网络</a> <a href="/tags/梯度下降/" style="font-size: 15px;">梯度下降</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a> <a href="/tags/数据处理/" style="font-size: 15px;">数据处理</a> <a href="/tags/Panadas/" style="font-size: 15px;">Panadas</a> <a href="/tags/凸包/" style="font-size: 15px;">凸包</a> <a href="/tags/随机算法/" style="font-size: 15px;">随机算法</a> <a href="/tags/sklearn/" style="font-size: 15px;">sklearn</a> <a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a> <a href="/tags/tensorboard/" style="font-size: 15px;">tensorboard</a> <a href="/tags/dropout/" style="font-size: 15px;">dropout</a> <a href="/tags/CNN/" style="font-size: 15px;">CNN</a> <a href="/tags/RNN/" style="font-size: 15px;">RNN</a> <a href="/tags/搜索/" style="font-size: 15px;">搜索</a> <a href="/tags/VC维/" style="font-size: 15px;">VC维</a> <a href="/tags/VPN/" style="font-size: 15px;">VPN</a> <a href="/tags/字符串/" style="font-size: 15px;">字符串</a> <a href="/tags/堆/" style="font-size: 15px;">堆</a> <a href="/tags/STL/" style="font-size: 15px;">STL</a> <a href="/tags/vector/" style="font-size: 15px;">vector</a> <a href="/tags/数组/" style="font-size: 15px;">数组</a> <a href="/tags/位运算/" style="font-size: 15px;">位运算</a> <a href="/tags/链表/" style="font-size: 15px;">链表</a> <a href="/tags/递归和循环/" style="font-size: 15px;">递归和循环</a> <a href="/tags/代码的完整性/" style="font-size: 15px;">代码的完整性</a> <a href="/tags/代码的鲁棒性/" style="font-size: 15px;">代码的鲁棒性</a> <a href="/tags/抽象具体化/" style="font-size: 15px;">抽象具体化</a> <a href="/tags/举例让抽象具体化/" style="font-size: 15px;">举例让抽象具体化</a> <a href="/tags/分解让复杂问题简单/" style="font-size: 15px;">分解让复杂问题简单</a> <a href="/tags/时间效率/" style="font-size: 15px;">时间效率</a> <a href="/tags/指针/" style="font-size: 15px;">指针</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/RBM/" style="font-size: 15px;">RBM</a> <a href="/tags/DBN/" style="font-size: 15px;">DBN</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">七月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Baidu Site Haritası</a> |  <a href="/atom.xml">订阅</a> |  <a href="/about/">关于</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次</p><p><span> Copyright &copy;<a href="/." rel="nofollow">Xu Shanshan.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script></body></html>